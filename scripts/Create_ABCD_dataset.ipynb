{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ppcor)\n",
    "#install.packages('lmPerm')\n",
    "library(lmPerm)\n",
    "library(psych)\n",
    "library(car)\n",
    "library(ggplot2)\n",
    "library(lme4)\n",
    "library(mediation)\n",
    "library(caret)\n",
    "library(gbm)\n",
    "library(party)\n",
    "library(Metrics)\n",
    "#install.packages(\"wesanderson\")\n",
    "library(wesanderson)\n",
    "library(gtools)\n",
    "library(interactions)\n",
    "#install.packages('ggstance')\n",
    "library(ggstance)\n",
    "#install.packages('elasticnet')\n",
    "#library(elasticnet)\n",
    "#install.packages('kernlab')\n",
    "#library(kernlab)\n",
    "#install.packages('e1071')\n",
    "#library(e1071)\n",
    "#install.packages('MatchIt')\n",
    "library(MatchIt)\n",
    "library(dplyr)\n",
    "library(ukbtools)\n",
    "library(mediation)\n",
    "library(lavaan)\n",
    "#install.packages('MissMech')\n",
    "#library(semTools)\n",
    "#library(MissMech)\n",
    "#install.packages('fsbrain')\n",
    "#install.packages('ipw')\n",
    "library(ipw)\n",
    "#install.packages('episensr')\n",
    "#install.packages('measurements')\n",
    "library(measurements)\n",
    "library(tidyr)\n",
    "#library(optimx)\n",
    "#install.packages('devtools')\n",
    "library(devtools)\n",
    "#install.packages('childsds')\n",
    "library(childsds)\n",
    "library(neuroCombat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr <- read.table('/export01/data/fmorys/ABCD30/abcd_smrip101.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "smri <- read.table('/export01/data/fmorys/ABCD30/abcd_smrip101.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( smri ) <- colnames(hdr)\n",
    "smri=subset(smri, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/abcd_smrip201.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "smri2 <- read.table('/export01/data/fmorys/ABCD30/abcd_smrip201.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( smri2 ) <- colnames(hdr)\n",
    "smri2=subset(smri2, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/abcd_ant01.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "anthr <- read.table('/export01/data/fmorys/ABCD30/abcd_ant01.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( anthr ) <- colnames(hdr)\n",
    "anthr=subset(anthr, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/freesqc01.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "QC <- read.table('/export01/data/fmorys/ABCD30/freesqc01.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( QC ) <- colnames(hdr)\n",
    "QC=subset(QC, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/acspsw03.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "fam <- read.table('/export01/data/fmorys/ABCD30/acspsw03.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( fam ) <- colnames(hdr)\n",
    "fam=subset(fam, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "prs=read.table('/dagher/dagher11/filip/ABCD_data/ABCD_BMI-PRS_Euro_nodup_zscore.csv',header=T, sep=',')\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/pdem02.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "ses <- read.table('/export01/data/fmorys/ABCD30/pdem02.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( ses ) <- colnames(hdr)\n",
    "ses=subset(ses, select=-c(dataset_id, interview_date, collection_id, src_subject_id, eventname, interview_age)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/mri_rsi_p102.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "rsi <- read.table('/export01/data/fmorys/ABCD30/mri_rsi_p102.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( rsi ) <- colnames(hdr)\n",
    "rsi=subset(rsi, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/mri_rsi_p202.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "rsi1 <- read.table('/export01/data/fmorys/ABCD30/mri_rsi_p202.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( rsi1 ) <- colnames(hdr)\n",
    "rsi1=subset(rsi1, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/abcd_lt01.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "lt <- read.table('/export01/data/fmorys/ABCD30/abcd_lt01.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( lt ) <- colnames(hdr)\n",
    "lt=subset(lt, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/abcd_mri01.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "mri <- read.table('/export01/data/fmorys/ABCD30/abcd_mri01.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( mri ) <- colnames(hdr)\n",
    "mri=subset(mri, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/abcd_dti_p101.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "dti <- read.table('/export01/data/fmorys/ABCD30/abcd_dti_p101.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( dti ) <- colnames(hdr)\n",
    "dti=subset(dti, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n",
    "\n",
    "hdr <- read.table('/export01/data/fmorys/ABCD30/dmriqc01.txt', sep='\\t',header=T, quote='\"', stringsAsFactors = FALSE)\n",
    "dti_qc <- read.table('/export01/data/fmorys/ABCD30/dmriqc01.txt', sep='\\t',header=F, quote='\"', skip = 2)\n",
    "colnames( dti_qc ) <- colnames(hdr)\n",
    "dti_qc=subset(dti_qc, select=-c(dataset_id, interview_date, collection_id, src_subject_id)) #Remove unnecessary columns for quicker merging further on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data files and leave only subjects with PRS and baseline and 1st follow-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri=mri[mri$eventname=='baseline_year_1_arm_1',]\n",
    "mri=mri[!duplicated(mri$subjectkey),]\n",
    "QC=QC[QC$eventname=='baseline_year_1_arm_1',]\n",
    "QC=QC[!duplicated(QC$subjectkey),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD=merge(smri,smri2, all.x=TRUE)\n",
    "ABCD=merge(ABCD, rsi, all.x=TRUE)\n",
    "ABCD=merge(ABCD, rsi1, all.x=TRUE)\n",
    "ABCD=merge(ABCD, mri, all.x=TRUE)\n",
    "ABCD=merge(ABCD, dti, all.x=TRUE)\n",
    "ABCD=merge(ABCD, dti_qc, all.x=TRUE)\n",
    "ABCD=ABCD[!(ABCD$eventname=='2_year_follow_up_y_arm_1' | ABCD$eventname=='1_year_follow_up_y_arm_1'),] #exclude the follow-ups from the structural dataset\n",
    "ABCD=merge(select(ABCD, -c(eventname, interview_age, abcd_smrip101_id, abcd_smrip201_id, smri_visitid)),anthr, all.x=TRUE)\n",
    "ABCD=merge(ABCD,prs,by.x='subjectkey',by.y='IID', all.x=TRUE)\n",
    "ABCD=merge(ABCD,ses,all.x=TRUE)\n",
    "ABCD=merge(ABCD,select(QC,-c(eventname)), all.x=TRUE)\n",
    "ABCD=merge(ABCD,fam, all.x=TRUE)\n",
    "ABCD=ABCD[(ABCD$fsqc_qc==1 || is.na(ABCD$fsqc_qc)),] # important because there are NA values for QC for 1 year f-up\n",
    "#ABCD=ABCD[complete.cases(ABCD$Z),] #only participants with PRS\n",
    "ABCD=merge(ABCD,lt,all.x=T)\n",
    "ABCD=ABCD[!ABCD$eventname=='2_year_follow_up_y_arm_1',] #exclude the third follow-up from the dataset\n",
    "nrow(ABCD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace NAs in family IDs with a random unique number for lmer analysis - not used - all related individuals are excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD$rel_family_id[is.na(ABCD$rel_family_id)] <- sample(1:sum(is.na(ABCD$rel_family_id)))*0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD$BMI=conv_unit(ABCD$anthroweightcalc,\"lbs\",\"kg\")/(conv_unit(ABCD$anthroheightcalc,\"inch\",\"m\")^2)\n",
    "ABCD$age_yrs=ABCD$interview_age/12\n",
    "ABCD$weight_kg=conv_unit(ABCD$anthroweightcalc,\"lbs\",\"kg\")\n",
    "ABCD$height_cm=conv_unit(ABCD$anthroheightcalc,\"inch\",\"cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove extreme values (Rapuano 2020 PNAS) and NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD=(ABCD[!((ABCD$BMI)>50 | is.na(ABCD$BMI)),])\n",
    "ABCD=(ABCD[!((ABCD$BMI)<10 | is.na(ABCD$BMI)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert values to SD and z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD$BMI_SD=sds(value = ABCD$BMI, age = ABCD$age_yrs, sex = ABCD$sex, male = \"M\", female = \"F\",ref = cdc.ref, item = \"bmi\",type = \"SDS\")\n",
    "\n",
    "ABCD$weight_SD=sds(value = ABCD$weight_kg, age = ABCD$age_yrs, sex = ABCD$sex, male = \"M\", female = \"F\", type = \"SDS\", ref = cdc.ref, item = \"weight2_20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct variables for TIV and scale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in c(grep('smri_vol_cdk',colnames(ABCD)))) {\n",
    "    ABCD[[i]]=scale(ABCD[[i]]/ABCD$smri_vol_scs_intracranialv)\n",
    "    }\n",
    "\n",
    "\n",
    "for (i in c(grep('smri_vol_scs',colnames(ABCD)))) {\n",
    "    ABCD[[i]]=scale(ABCD[[i]]/ABCD$smri_vol_scs_intracranialv)\n",
    "    }\n",
    "\n",
    "\n",
    "for (i in c(grep('smri_area_cdk',colnames(ABCD)))) {\n",
    "    ABCD[[i]]=scale(ABCD[[i]])\n",
    "    }\n",
    "\n",
    "\n",
    "for (i in c(grep('smri_thick_cdk',colnames(ABCD)))) {\n",
    "    ABCD[[i]]=scale(ABCD[[i]])\n",
    "    }\n",
    "\n",
    "for (i in c(grep('dtifa_fiberat',colnames(ABCD)))) {\n",
    "    ABCD[[i]]=scale(ABCD[[i]])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run COMBAT on all thickness and volume data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD=ABCD[complete.cases(ABCD$mri_info_manufacturer), ]\n",
    "dat=as.matrix(ABCD[c(grep('smri_vol_cdk',colnames(ABCD)),\n",
    "                     grep('smri_thick_cdk',colnames(ABCD)),\n",
    "                     grep('smri_vol_scs',colnames(ABCD))[c(1:9,13:14,17,24:29,31)],\n",
    "                     grep('dtifa_fiberat',colnames(ABCD)),\n",
    "                    grep('smri_area_cdk',colnames(ABCD)))]) #\n",
    "dat_t=t(dat)\n",
    "batch=as.vector(as.numeric((ABCD$mri_info_manufacturer)))\n",
    "age=as.vector(as.numeric(ABCD$age_yrs))\n",
    "sex=as.vector(as.factor(ABCD$sex))\n",
    "bmisd=as.vector(as.numeric(ABCD$BMI_SD))\n",
    "mod <- model.matrix(~age+sex+bmisd)\n",
    "combat.harmonized <- neuroCombat(dat=dat_t, batch=batch, mod=mod)\n",
    "data_back=as.data.frame(t(combat.harmonized$dat.combat))\n",
    "colnames(data_back)=paste(\"H\", colnames(data_back), sep = \"_\")\n",
    "ABCD=cbind(ABCD,data_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD=ABCD[complete.cases(ABCD$mri_info_manufacturer), ]\n",
    "dat=as.matrix(ABCD[c(grep('smri_vol_cdk',colnames(ABCD)),\n",
    "                     grep('smri_thick_cdk',colnames(ABCD)),\n",
    "                     grep('smri_vol_scs',colnames(ABCD))[c(1:9,13:14,17,24:29,31)],\n",
    "                     grep('dtifa_fiberat',colnames(ABCD)),\n",
    "                    grep('smri_area_cdk',colnames(ABCD)))]) #\n",
    "dat_t=t(dat)\n",
    "batch=as.vector(as.numeric((ABCD$site_id_l)))\n",
    "age=as.vector(as.numeric(ABCD$age_yrs))\n",
    "sex=as.vector(as.factor(ABCD$sex))\n",
    "bmisd=as.vector(as.numeric(ABCD$BMI_SD))\n",
    "mod <- model.matrix(~age+sex+bmisd)\n",
    "combat.harmonized <- neuroCombat(dat=dat_t, batch=batch, mod=mod)\n",
    "data_back=as.data.frame(t(combat.harmonized$dat.combat))\n",
    "colnames(data_back)=paste(\"H_site\", colnames(data_back), sep = \"_\")\n",
    "ABCD=cbind(ABCD,data_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If creating dataset with only baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD_baseline_only=ABCD[ABCD$eventname=='baseline_year_1_arm_1',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(ABCD_baseline_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.table(ABCD_baseline_only,'/dagher/dagher9/filip/ABCD_data_harmonised/ABCD_baseline.csv',sep=',',dec='.',quote=FALSE, \n",
    "           col.names=T, row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If creating longitudinal datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD=ABCD[complete.cases(c(ABCD[grep('BMI',colnames(ABCD), grep('weight',colnames(ABCD)),\n",
    "                                    grep('waist',colnames(ABCD)), grep('hip',colnames(ABCD)) )])),]\n",
    "\n",
    "ABCD=(ABCD[ABCD$subjectkey %in% names(which(table(ABCD$subjectkey) == 2)), ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset with baseline and follow-up measures\n",
    "\n",
    "### Variables with .x are baseline and .y are follow-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fup=ABCD[ABCD$eventname=='1_year_follow_up_y_arm_1',]\n",
    "ABCD2=ABCD[ABCD$eventname=='baseline_year_1_arm_1',]\n",
    "fup1=merge(ABCD2, fup, by='subjectkey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate deltas, remove extreme values (Rapuano 2020, PNAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fup1$deltaBMI=fup1$BMI.y-fup1$BMI.x\n",
    "fup1$deltaW=fup1$anthroweightcalc.y-fup1$anthroweightcalc.x\n",
    "fup1$deltaWaist=fup1$anthro_waist_cm.y-fup1$anthro_waist_cm.x\n",
    "fup1$deltaBMI_SD=fup1$BMI_SD.y-fup1$BMI_SD.x\n",
    "fup1$deltaweight_SD=fup1$weight_SD.y-fup1$weight_SD.x\n",
    "\n",
    "excluded=subset(fup1, deltaW > 50 | deltaW < -20 ) # Get IDs of participants excluded from here for ABCD dataset\n",
    "fup1=subset(fup1, deltaW <= 50 & deltaW >= -20 | is.na(deltaW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove participants with extreme values from the ABCD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps <- apply(ABCD, 1, function(x) !any(x %in% excluded$subjectkey))\n",
    "               \n",
    "ABCD=ABCD[keeps,]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(ABCD)\n",
    "nrow(fup1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write.table(fup1,'/dagher/dagher11/filip/PRSOB/data/ABCD_base_fup1_wide_full.csv',sep=',',dec='.',quote=FALSE, \n",
    "#           col.names=T, row.names=F)\n",
    "\n",
    "write.table(ABCD,'/dagher/dagher11/filip/PRSOB/data/ABCD_base_fup1_long_full.csv',sep=',',dec='.',quote=FALSE, \n",
    "           col.names=T, row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If creating a dataset with 3 timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD=(ABCD[ABCD$subjectkey %in% names(which(table(ABCD$subjectkey) == 3)), ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write datasets with 3 timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fup=ABCD[ABCD$eventname=='2_year_follow_up_y_arm_1',]\n",
    "ABCD2=ABCD[ABCD$eventname=='baseline_year_1_arm_1',]\n",
    "fup1=merge(ABCD2, fup, by='subjectkey')\n",
    "\n",
    "fup1$deltaBMI=fup1$BMI.y-fup1$BMI.x\n",
    "fup1$deltaW=fup1$anthroweightcalc.y-fup1$anthroweightcalc.x\n",
    "fup1$deltaWaist=fup1$anthro_waist_cm.y-fup1$anthro_waist_cm.x\n",
    "fup1$deltaBMI_SD=fup1$BMI_SD.y-fup1$BMI_SD.x\n",
    "fup1$deltaweight_SD=fup1$weight_SD.y-fup1$weight_SD.x\n",
    "\n",
    "excluded=subset(fup1, deltaW > 50 | deltaW < -20 ) # Get IDs of participants excluded from here for ABCD dataset\n",
    "fup1=subset(fup1, deltaW <= 50 & deltaW >= -20 | is.na(deltaW))\n",
    "\n",
    "keeps <- apply(ABCD, 1, function(x) !any(x %in% excluded$subjectkey))\n",
    "               \n",
    "ABCD=ABCD[keeps,]        \n",
    "               \n",
    "nrow(ABCD)\n",
    "nrow(fup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.table(ABCD,'/dagher/dagher11/filip/PRSOB/data/ABCD_base_fup1and2_long.csv',sep=',',dec='.',quote=T, \n",
    "           col.names=T, row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
